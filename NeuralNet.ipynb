{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "652fce88",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks\n",
    "\n",
    "ip-biocode $\\cdot$ March 26, 2022\n",
    "\n",
    "In this exercise, I build a neural network from scratch and code how it performs predictions using forward propagation. This is only to help with understanding the underlying mechanisms. All deep learning libraries have the entire training and prediction processes implemented, and so in practice you wouldn't really need to build a neural network from scratch.\n",
    "\n",
    "## Forward Propagation: Simple Example\n",
    "\n",
    "<img src=\"http://cocl.us/neural_network_example\" alt=\"Neural Network Example\" width=600px>\n",
    "\n",
    "Here is a simple neural network that takes two inputs, has one hidden layer with two nodes, and an output layer with one node.\n",
    "\n",
    "### Initialize weights and biases\n",
    "Begin by randomly initializing weights and biases in the network. We have 6 weights and 3 biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecaf6b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95 0.02 0.92 0.23 0.5  0.12]\n",
      "[0.43 0.25 0.47]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "weights = np.around(np.random.uniform(size=6), decimals=2)\n",
    "biases = np.around(np.random.uniform(size=3), decimals=2)\n",
    "\n",
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad20b77",
   "metadata": {},
   "source": [
    "### Compute weighted sums\n",
    "Now that we have the weights and the biases defined for the network, let's compute the output for a given input, $x\\_1$ and $x\\_2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29fd9bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 is 0.5 and x2 is 0.85\n"
     ]
    }
   ],
   "source": [
    "x_1 = 0.5 # input 1\n",
    "x_2 = 0.85 # input 2\n",
    "\n",
    "print('x1 is {} and x2 is {}'.format(x_1, x_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3417358a",
   "metadata": {},
   "source": [
    "Compute the wighted sum of the inputs at the first node of the hidden layer, $z_{1, 1}$. The weights are $w_1$ and $w_2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c858f08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the inputs at the first node in the hidden layer is 0.9219999999999999\n"
     ]
    }
   ],
   "source": [
    "z_11 = x_1 * weights[0] + x_2 * weights[1] + biases[0]\n",
    "\n",
    "print('The weighted sum of the inputs at the first node in the hidden layer is {}'.format(z_11))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1e2de",
   "metadata": {},
   "source": [
    "Next compute the weighted sum of the inputs at the second node of the hidden layer, $z_{1, 2}$. The weights are $w_3$ and $w_4$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "020aac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the inputs at the first node in the hidden layer is 0.9055\n"
     ]
    }
   ],
   "source": [
    "z_12 = x_1 * weights[2] + x_2 * weights[3] + biases[1]\n",
    "\n",
    "print('The weighted sum of the inputs at the first node in the hidden layer is {}'.format(z_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec389e",
   "metadata": {},
   "source": [
    "### Compute node activation\n",
    "Next, assuming a sigmoid activation function, compute the activation of the first node, $a_{1, 1}$, in the hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c1223d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the first node in the hidden layer is 0.7154\n"
     ]
    }
   ],
   "source": [
    "a_11 = 1.0 / (1.0 + np.exp(-z_11))\n",
    "\n",
    "print('The activation of the first node in the hidden layer is {}'.format(np.around(a_11, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8d9d65",
   "metadata": {},
   "source": [
    "Compute the activation of the second node, $a_{1, 2}$, in the hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc4eb39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the first node in the hidden layer is 0.7121\n"
     ]
    }
   ],
   "source": [
    "a_12 = 1.0 / (1.0 + np.exp(-z_12))\n",
    "\n",
    "print('The activation of the first node in the hidden layer is {}'.format(np.around(a_12, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10b4cbd",
   "metadata": {},
   "source": [
    "Now these activations will serve as the inputs to the output layer. Compute the weighted sum of these inputs to the node in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f4d9017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the inputs at the node in the output layer is 1.0397\n"
     ]
    }
   ],
   "source": [
    "z_2 = z_11*weights[4] + z_12*weights[5] + biases[2]\n",
    "\n",
    "print('The weighted sum of the inputs at the node in the output layer is {}'.format(np.around(z_2, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc6fa52",
   "metadata": {},
   "source": [
    "Finally, compute the output of the network as the activation of the node in the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bd531be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the network for x1=0.5 and x2=0.85 is 0.7388\n"
     ]
    }
   ],
   "source": [
    "a_2 = 1.0 / (1.0 + np.exp(-z_2))\n",
    "\n",
    "print('The output of the network for x1=0.5 and x2=0.85 is {}'.format(np.around(a_2, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc34846a",
   "metadata": {},
   "source": [
    "## A General Network\n",
    "Obviously, neural networks for real problems are composed of many hidden layers and many more nodes in each layer. So, we can't continue making predictions using this very inefficient approach of computing the weighted sum at each node and the activation of each node manually.\n",
    "\n",
    "In order to make predictions automatically, we should generalize our network. A general network would take $n$ inputs, would have many hidden layers, each hidden layer having $m$ nodes, and would have an output layer. Although the network is showing one hidden layer, we will code the network to have many hidden layers. Similarly, although the network shows an output layer with one node, we will code the network to have more than one node in the output layer.\n",
    "\n",
    "<img src=\"http://cocl.us/general_neural_network\" alt=\"Neural Network General\" width=600px>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f733d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
