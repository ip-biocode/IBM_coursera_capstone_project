{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ee0c8e",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks\n",
    "\n",
    "ip-biocode $\\cdot$ March 26, 2022\n",
    "\n",
    "In this exercise, I build a neural network from scratch and code how it performs predictions using forward propagation. This is only to help with understanding the underlying mechanisms. All deep learning libraries have the entire training and prediction processes implemented, and so in practice you wouldn't really need to build a neural network from scratch.\n",
    "\n",
    "## Forward Propagation: Simple Example\n",
    "\n",
    "<img src=\"http://cocl.us/neural_network_example\" alt=\"Neural Network Example\" width=600px>\n",
    "\n",
    "Here is a simple neural network that takes two inputs, has one hidden layer with two nodes, and an output layer with one node.\n",
    "\n",
    "### Initialize weights and biases\n",
    "Begin by randomly initializing weights and biases in the network. We have 6 weights and 3 biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91210fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92 0.9  0.03 0.96 0.14 0.28]\n",
      "[0.61 0.94 0.85]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "weights = np.around(np.random.uniform(size=6), decimals=2)\n",
    "biases = np.around(np.random.uniform(size=3), decimals=2)\n",
    "\n",
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1156714",
   "metadata": {},
   "source": [
    "### Compute weighted sums\n",
    "Now that we have the weights and the biases defined for the network, let's compute the output for a given input, $x\\_1$ and $x\\_2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1918e1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 is 0.5 and x2 is 0.85\n"
     ]
    }
   ],
   "source": [
    "x_1 = 0.5 # input 1\n",
    "x_2 = 0.85 # input 2\n",
    "\n",
    "print('x1 is {} and x2 is {}'.format(x_1, x_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6065e87c",
   "metadata": {},
   "source": [
    "Compute the wighted sum of the inputs at the first node of the hidden layer, $z_{1, 1}$. The weights are $w_1$ and $w_2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a38e961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the inputs at the first node in the hidden layer is 0.9219999999999999\n"
     ]
    }
   ],
   "source": [
    "z_11 = x_1 * weights[0] + x_2 * weights[1] + biases[0]\n",
    "\n",
    "print('The weighted sum of the inputs at the first node in the hidden layer is {}'.format(z_11))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffde4e89",
   "metadata": {},
   "source": [
    "Next compute the weighted sum of the inputs at the second node of the hidden layer, $z_{1, 2}$. The weights are $w_3$ and $w_4$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e46596f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the inputs at the first node in the hidden layer is 0.9055\n"
     ]
    }
   ],
   "source": [
    "z_12 = x_1 * weights[2] + x_2 * weights[3] + biases[1]\n",
    "\n",
    "print('The weighted sum of the inputs at the first node in the hidden layer is {}'.format(z_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd814021",
   "metadata": {},
   "source": [
    "### Compute node activation\n",
    "Next, assuming a sigmoid activation function, compute the activation of the first node, $a_{1, 1}$, in the hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b2dab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the first node in the hidden layer is 0.7154\n"
     ]
    }
   ],
   "source": [
    "a_11 = 1.0 / (1.0 + np.exp(-z_11))\n",
    "\n",
    "print('The activation of the first node in the hidden layer is {}'.format(np.around(a_11, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63263b",
   "metadata": {},
   "source": [
    "Compute the activation of the second node, $a_{1, 2}$, in the hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35e2ef13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the first node in the hidden layer is 0.7121\n"
     ]
    }
   ],
   "source": [
    "a_12 = 1.0 / (1.0 + np.exp(-z_12))\n",
    "\n",
    "print('The activation of the first node in the hidden layer is {}'.format(np.around(a_12, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad97b856",
   "metadata": {},
   "source": [
    "Now these activations will serve as the inputs to the output layer. Compute the weighted sum of these inputs to the node in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf9f4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the inputs at the node in the output layer is 1.0397\n"
     ]
    }
   ],
   "source": [
    "z_2 = z_11*weights[4] + z_12*weights[5] + biases[2]\n",
    "\n",
    "print('The weighted sum of the inputs at the node in the output layer is {}'.format(np.around(z_2, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32f3b11",
   "metadata": {},
   "source": [
    "Finally, compute the output of the network as the activation of the node in the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb007dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the network for x1=0.5 and x2=0.85 is 0.7388\n"
     ]
    }
   ],
   "source": [
    "a_2 = 1.0 / (1.0 + np.exp(-z_2))\n",
    "\n",
    "print('The output of the network for x1=0.5 and x2=0.85 is {}'.format(np.around(a_2, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7238e83",
   "metadata": {},
   "source": [
    "## A General Network\n",
    "Obviously, neural networks for real problems are composed of many hidden layers and many more nodes in each layer. So, we can't continue making predictions using this very inefficient approach of computing the weighted sum at each node and the activation of each node manually.\n",
    "\n",
    "In order to make predictions automatically, we should generalize our network. A general network would take $n$ inputs, would have many hidden layers, each hidden layer having $m$ nodes, and would have an output layer. Although the network is showing one hidden layer, we will code the network to have many hidden layers. Similarly, although the network shows an output layer with one node, we will code the network to have more than one node in the output layer.\n",
    "\n",
    "<img src=\"http://cocl.us/general_neural_network\" alt=\"Neural Network General\" width=600px>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29ec6f3",
   "metadata": {},
   "source": [
    "### Initialize network\n",
    "\n",
    "Define structure of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ce4a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 # inputs\n",
    "num_hidden_layers = 2 # hidden layers\n",
    "m = [2, 2] # nodes in each hidden layer\n",
    "num_nodes_output = 1 # nodes in output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fdbca1",
   "metadata": {},
   "source": [
    "Initialize weights and biases with random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "191d36a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.34, 0.79]), 'bias': array([0.85])}, 'node_2': {'weights': array([0.37, 0.72]), 'bias': array([0.18])}}, 'layer_2': {'node_1': {'weights': array([0.49, 0.86]), 'bias': array([0.83])}, 'node_2': {'weights': array([0.42, 0.96]), 'bias': array([0.64])}}, 'output': {'node_1': {'weights': array([0.09, 0.04]), 'bias': array([0.29])}}}\n"
     ]
    }
   ],
   "source": [
    "num_nodes_previous = n # nodes in the previous layer\n",
    "\n",
    "network = {} # initialize network as an empty dictionary\n",
    "\n",
    "# loop through each layer\n",
    "# Adding 1 to number of hidden layers for output layer\n",
    "for layer in range(num_hidden_layers + 1): \n",
    "    \n",
    "    # assign name of layer\n",
    "    if layer == num_hidden_layers:\n",
    "        layer_name = 'output'\n",
    "        num_nodes = num_nodes_output\n",
    "    else:\n",
    "        layer_name = 'layer_{}'.format(layer + 1)\n",
    "        num_nodes = m[layer]\n",
    "    \n",
    "    # initialize weights and biases in current layer\n",
    "    network[layer_name] = {}\n",
    "    for node in range(num_nodes):\n",
    "        node_name = 'node_{}'.format(node+1)\n",
    "        network[layer_name][node_name] = {\n",
    "            'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "            'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "        }\n",
    "    \n",
    "    num_nodes_previous = num_nodes\n",
    "    \n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aa9913",
   "metadata": {},
   "source": [
    "Now we are able to initialize the weights and the biases pertaining to any network of any number of hidden layers and number of nodes in each layer. I will put this code in a function so that we are able to repetitively execute all this code whenever we want to construct a neural network.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "feb23f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(num_inputs, num_hidden_layers, num_nodes_hidden, num_nodes_output):\n",
    "    \n",
    "    num_nodes_previous = num_inputs # number of nodes in the previous layer\n",
    "\n",
    "    network = {}\n",
    "    \n",
    "    # loop through each layer and randomly initialize the weights and biases associated with each layer\n",
    "    for layer in range(num_hidden_layers + 1):\n",
    "        \n",
    "        if layer == num_hidden_layers:\n",
    "            layer_name = 'output' # name last layer in the network output\n",
    "            num_nodes = num_nodes_output\n",
    "        else:\n",
    "            layer_name = 'layer_{}'.format(layer + 1) # otherwise give the layer a number\n",
    "            num_nodes = num_nodes_hidden[layer] \n",
    "        \n",
    "        # initialize weights and bias for each node\n",
    "        network[layer_name] = {}\n",
    "        for node in range(num_nodes):\n",
    "            node_name = 'node_{}'.format(node+1)\n",
    "            network[layer_name][node_name] = {\n",
    "                'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "                'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "            }\n",
    "    \n",
    "        num_nodes_previous = num_nodes\n",
    "\n",
    "    return network # return the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e06448",
   "metadata": {},
   "source": [
    "#### Use the *initialize_network* function to create a network that:\n",
    "\n",
    "1.  takes 5 inputs\n",
    "2.  has three hidden layers\n",
    "3.  has 3 nodes in the first layer, 2 nodes in the second layer, and 3 nodes in the third layer\n",
    "4.  has 1 node in the output layer\n",
    "\n",
    "Call the network **small_network**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a73872c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_network = initialize_network(5, 3, [3, 2, 3], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6f922",
   "metadata": {},
   "source": [
    "### Weighted sums\n",
    "\n",
    "The weighted sum at each node is computed as a dot product of the inputs and the weights plus the bias. So let's create a function called *compute_weighted_sum* that does just that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3e6e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_sum(inputs, weights, bias):\n",
    "    return np.sum(inputs*weights) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f96696f",
   "metadata": {},
   "source": [
    "First generate random input values for the five inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "652fceb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs to the network are [0.15 0.74 0.26 0.53 0.01]\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "\n",
    "np.random.seed(12)\n",
    "inputs = np.around(np.random.uniform(size=5), decimals=2)\n",
    "\n",
    "print('The inputs to the network are {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3200724b",
   "metadata": {},
   "source": [
    "Define weights and bias, and then compute weighted sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06840503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " small_network['layer_1']['node_1']['bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ff7487d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum at the first node in the hidden layer is 1.602\n"
     ]
    }
   ],
   "source": [
    "node_weights = small_network['layer_1']['node_1']['weights']\n",
    "node_bias = small_network['layer_1']['node_1']['bias']\n",
    "\n",
    "weighted_sum = compute_weighted_sum(inputs, node_weights, node_bias)\n",
    "\n",
    "print('The weighted sum at the first node in the hidden layer is {}'.format(np.around(weighted_sum[0], decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e46e504",
   "metadata": {},
   "source": [
    "### Compute node activation\n",
    "\n",
    "Recall that the output of each node is simply a non-linear tranformation of the weighted sum. We use activation functions for this mapping. Let's use the sigmoid function as the activation function here. So let's define a function that takes a weighted sum as input and returns the non-linear transformation of the input using the sigmoid function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b44c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_activation(weighted_sum):\n",
    "    return 1.0 / (1.0 + np.exp(-1 * weighted_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "883ecdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the first node in the hidden layer is 0.8323\n"
     ]
    }
   ],
   "source": [
    "node_output = node_activation(weighted_sum)\n",
    "\n",
    "print('The output of the first node in the hidden layer is {}'.format(np.around(node_output[0], decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269fb490",
   "metadata": {},
   "source": [
    "### Forward propagation\n",
    "\n",
    "The final piece of building a neural network that can perform predictions is to put everything together. So let's create a function that applies the *compute_weighted_sum* and *node_activation* functions to each node in the network and propagates the data all the way to the output layer and outputs a prediction for each node in the output layer.\n",
    "\n",
    "We will follow the following procedure:\n",
    "\n",
    "1.  Start with the input layer as the input to the first hidden layer.\n",
    "2.  Compute the weighted sum at the nodes of the current layer.\n",
    "3.  Compute the output of the nodes of the current layer.\n",
    "4.  Set the output of the current layer to be the input to the next layer.\n",
    "5.  Move to the next layer in the network.\n",
    "6.  Repeat steps 2 - 4 until we compute the output of the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fe74b189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(network, inputs):\n",
    "    \n",
    "    layer_inputs = list(inputs) # start with the input layer as the input to the first hidden layer\n",
    "    \n",
    "    for layer in network:\n",
    "        \n",
    "        layer_data = network[layer]\n",
    "        \n",
    "        layer_outputs = [] \n",
    "        for layer_node in layer_data:\n",
    "        \n",
    "            node_data = layer_data[layer_node]\n",
    "        \n",
    "            # compute the weighted sum and the output of each node at the same time \n",
    "            node_output = node_activation(compute_weighted_sum(layer_inputs, node_data['weights'], node_data['bias']))\n",
    "            layer_outputs.append(np.around(node_output[0], decimals=4))\n",
    "            \n",
    "        if layer != 'output':\n",
    "            print('The outputs of the nodes in hidden layer number {} is {}'.format(layer.split('_')[1], layer_outputs))\n",
    "    \n",
    "        layer_inputs = layer_outputs # set the output of this layer to be the input to next layer\n",
    "\n",
    "    network_predictions = layer_outputs\n",
    "    return network_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1119406",
   "metadata": {},
   "source": [
    "#### Use the *forward_propagate* function to compute the prediction of our small network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6a49c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs of the nodes in hidden layer number 1 is [0.8323, 0.8268, 0.7735]\n",
      "The outputs of the nodes in hidden layer number 2 is [0.7932, 0.8991]\n",
      "The outputs of the nodes in hidden layer number 3 is [0.8232, 0.8924, 0.8141]\n",
      "The predicted value by the network for the given input is 0.9112\n"
     ]
    }
   ],
   "source": [
    "predictions = forward_propagate(small_network, inputs)\n",
    "print('The predicted value by the network for the given input is {}'.format(np.around(predictions[0], decimals=4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e5a481",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We built the code to define a neural network from scratch. Now we can specify the number of inputs that a neural network can take, the number of hidden layers as well as the number of nodes in each hidden layer, and the number of nodes in the output layer.\n",
    "\n",
    "We first use the *initialize_network* to create our neural network and define its weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "764668fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_network = initialize_network(5, 3, [2, 3, 2], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec4d5bb",
   "metadata": {},
   "source": [
    "Then for a given input, we compute the network predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c4e25e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.around(np.random.uniform(size=5), decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2eefb177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs of the nodes in hidden layer number 1 is [0.8857, 0.8889]\n",
      "The outputs of the nodes in hidden layer number 2 is [0.7822, 0.6965, 0.7411]\n",
      "The outputs of the nodes in hidden layer number 3 is [0.868, 0.881]\n",
      "The predicted values by the network for the given input are [0.8952, 0.8222, 0.8035]\n"
     ]
    }
   ],
   "source": [
    "predictions = forward_propagate(my_network, inputs)\n",
    "print('The predicted values by the network for the given input are {}'.format(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
